{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6051ff5b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"start\")\n",
    "time.sleep(2)\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ce94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from utils.treebank import RTE_dataset\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import operator\n",
    "from word2vec import *\n",
    "from sgd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b183555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python Version\n",
    "import sys\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b938a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the random seed to make sure that everyone gets the same results\n",
    "random.seed(314)\n",
    "dataset = RTE_dataset()\n",
    "tokens = dataset.tokens()\n",
    "nWords = len(tokens)\n",
    "# print(type(dataset._tokenfreq))\n",
    "# sorted_d = sorted(dataset._tokenfreq.items(), key=operator.itemgetter(1), reverse=True)[:1000]\n",
    "# print('Dictionary in descending order by value : ',sorted_d)\n",
    "# We are going to train 10-dimensional vectors for this assignment\n",
    "dimVectors = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a0adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context size\n",
    "C = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beeb64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the random seed to make sure that everyone gets the same results\n",
    "random.seed(31415)\n",
    "np.random.seed(9265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ff37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10: 30.041006\n",
      "iter 20: 30.155375\n",
      "iter 30: 30.035286\n",
      "iter 40: 30.172813\n",
      "iter 50: 30.280590\n",
      "iter 60: 30.588848\n",
      "iter 70: 30.752065\n",
      "iter 80: 30.777511\n",
      "iter 90: 30.771174\n",
      "iter 100: 30.879536\n",
      "iter 110: 30.829980\n",
      "iter 120: 30.843909\n",
      "iter 130: 30.994379\n",
      "iter 140: 30.939082\n",
      "iter 150: 31.061922\n",
      "iter 160: 31.193862\n",
      "iter 170: 31.639449\n",
      "iter 180: 31.628145\n",
      "iter 190: 31.686043\n",
      "iter 200: 31.924036\n",
      "iter 210: 31.890878\n",
      "iter 220: 32.004243\n",
      "iter 230: 32.111945\n",
      "iter 240: 32.298134\n",
      "iter 250: 32.574122\n",
      "iter 260: 32.752452\n",
      "iter 270: 32.883754\n",
      "iter 280: 32.939844\n",
      "iter 290: 33.092270\n",
      "iter 300: 33.061698\n",
      "iter 310: 33.162288\n",
      "iter 320: 33.318813\n",
      "iter 330: 33.177805\n",
      "iter 340: 33.287820\n",
      "iter 350: 33.430463\n",
      "iter 360: 33.306735\n",
      "iter 370: 33.372169\n",
      "iter 380: 33.388609\n",
      "iter 390: 33.152606\n",
      "iter 400: 33.149521\n",
      "iter 410: 33.138977\n",
      "iter 420: 33.075578\n",
      "iter 430: 33.068722\n",
      "iter 440: 33.222334\n",
      "iter 450: 32.956525\n",
      "iter 460: 32.879374\n",
      "iter 470: 32.935684\n",
      "iter 480: 32.691824\n",
      "iter 490: 32.978615\n",
      "iter 500: 33.136688\n",
      "iter 510: 33.050529\n",
      "iter 520: 33.159290\n",
      "iter 530: 33.178721\n",
      "iter 540: 33.220074\n",
      "iter 550: 33.419501\n",
      "iter 560: 33.586008\n",
      "iter 570: 33.820486\n",
      "iter 580: 33.730638\n",
      "iter 590: 33.889278\n",
      "iter 600: 33.795953\n",
      "iter 610: 33.798787\n",
      "iter 620: 33.725247\n",
      "iter 630: 33.899361\n",
      "iter 640: 33.820827\n",
      "iter 650: 33.868199\n",
      "iter 660: 33.768326\n",
      "iter 670: 33.856412\n",
      "iter 680: 33.650422\n",
      "iter 690: 33.530974\n",
      "iter 700: 33.447935\n",
      "iter 710: 33.445316\n",
      "iter 720: 33.366523\n",
      "iter 730: 33.482238\n",
      "iter 740: 33.714207\n",
      "iter 750: 33.904133\n",
      "iter 760: 34.038794\n",
      "iter 770: 33.915172\n",
      "iter 780: 34.072164\n",
      "iter 790: 34.183236\n",
      "iter 800: 34.288702\n",
      "iter 810: 34.099235\n",
      "iter 820: 34.071611\n",
      "iter 830: 33.992035\n",
      "iter 840: 34.145147\n",
      "iter 850: 33.985615\n",
      "iter 860: 34.078135\n",
      "iter 870: 33.998253\n",
      "iter 880: 33.769866\n",
      "iter 890: 33.705427\n"
     ]
    }
   ],
   "source": [
    "startTime=time.time()\n",
    "wordVectors = np.concatenate(\n",
    "    ((np.random.rand(nWords, dimVectors) - 0.5) /\n",
    "       dimVectors, np.zeros((nWords, dimVectors))),\n",
    "    axis=0)\n",
    "wordVectors = sgd(\n",
    "    lambda vec: word2vec_sgd_wrapper(skipgram, tokens, vec, dataset, C,\n",
    "        negSamplingLossAndGradient),\n",
    "    wordVectors, 0.3, 20010, None, True, PRINT_EVERY=10)\n",
    "# Note that normalization is not called here. This is not a bug,\n",
    "# normalizing during training loses the notion of length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db196469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity check: cost at convergence should be around or below 20\n",
      "training took 44108 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"sanity check: cost at convergence should be around or below 20\")\n",
    "print(\"training took %d seconds\" % (time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22c6b598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48858, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c81d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the input and output word vectors\n",
    "wordVectors = np.concatenate(\n",
    "    (wordVectors[:nWords,:], wordVectors[nWords:,:]),\n",
    "    axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e1b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizeWords = [\n",
    "#     \"great\", \"cool\",  \"wonderful\", \"well\", \"amazing\",\n",
    "#     \"worth\", \"sweet\",   \"bad\", \"eat\", \"eating\", \"meet\", \"meeting\"\n",
    "#      \"female\", \"male\", \"queen\", \"king\", \"man\", \"woman\", \"rain\", \"snow\",\n",
    "#      \"coffee\", \"tea\"]\n",
    "visualizeWords = [\n",
    "    \"thursday\", \"work\", 'security', \"tuesday\", \"friday\", \"monday\", \"sunday\",\"iraq\",\"iraqi\", \"russia\",\"russian\", \"authorities\",\n",
    "    \"war\", \"european\", \"northern\", \"southern\", \"january\", \"august\", \"chief\", \n",
    "    \"palestinian\", \"commission\", \"white\", \"black\", \"party\", \"south\", \"north\", \"television\", \"computer\", \"service\", \"spokesman\"\n",
    "    ]\n",
    "visualizeIdx = [tokens[word] for word in visualizeWords]\n",
    "visualizeVecs = wordVectors[visualizeIdx, :]\n",
    "temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n",
    "covariance = 1.0 / len(visualizeIdx) * temp.T.dot(temp)\n",
    "U,S,V = np.linalg.svd(covariance)\n",
    "coord = temp.dot(U[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced45060",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(visualizeWords)):\n",
    "    plt.text(coord[i,0], coord[i,1], visualizeWords[i],\n",
    "        bbox=dict(facecolor='green', alpha=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1687e647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2772434944.0, 5049942016.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.xlim((np.min(coord[:,0]), np.max(coord[:,0])))\n",
    "plt.ylim((np.min(coord[:,1]), np.max(coord[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b90a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('word_vectors.png')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
